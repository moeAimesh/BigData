{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ebbfe77",
   "metadata": {},
   "source": [
    "# Image Feature Loader & DB-Saver\n",
    "Dieses Notebook lädt Bilder, extrahiert Features und speichert sie in einer SQLite-Datenbank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8193981",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from loader import image_generator\n",
    "from features.hash import calc_hash\n",
    "from features.color_vec import calc_histogram\n",
    "from features.embedding_vec import extract_embeddings\n",
    "from image_load import fast_load\n",
    "import traceback\n",
    "from sklearn.decomposition import PCA\n",
    "import umap\n",
    "import cProfile\n",
    "import pstats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1549cfc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Verarbeitung: 100%|██████████| 258/258 [00:10<00:00, 25.19Bild/s] \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ========== CONFIG ==========\n",
    "DB_PATH = r\"Z:\\CODING\\UNI\\BIG_DATA\\data\\database.db\"\n",
    "PHOTO_FOLDER = r\"D:\\Test_bilder_verschachtelt\"\n",
    "EMBEDDING_DIR = r\"Z:\\CODING\\UNI\\BIG_DATA\\embeddings\"\n",
    "EMBEDDING_PCA_DIR = r\"Z:\\CODING\\UNI\\BIG_DATA\\embeddings_pca\"  # <<< HINZUGEFÜGT\n",
    "BATCH_SIZE = 1024\n",
    "MAX_WORKERS = os.cpu_count() - 1\n",
    "TABLE_NAME = \"image_features_test\"\n",
    "LOG_FILE = \"verarbeitung_log.txt\"\n",
    "\n",
    "Path(EMBEDDING_DIR).mkdir(parents=True, exist_ok=True)\n",
    "Path(EMBEDDING_PCA_DIR).mkdir(parents=True, exist_ok=True)  # <<< HINZUGEFÜGT\n",
    "\n",
    "# ========== DB ==========\n",
    "conn = sqlite3.connect(DB_PATH)\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"PRAGMA journal_mode=OFF;\")\n",
    "cursor.execute(\"PRAGMA synchronous=OFF;\")\n",
    "\n",
    "def save_batch_to_db(entries):\n",
    "    cursor.executemany(f\"\"\"\n",
    "        INSERT OR REPLACE INTO {TABLE_NAME}\n",
    "        (filename, path, color_hist, embedding_path, image_hash, resolution, file_size,\n",
    "         category, photographer, pca_embedding, umap_x, umap_y)\n",
    "        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "    \"\"\", entries)\n",
    "    conn.commit()\n",
    "\n",
    "# ========== Feature-Extractor Threaded ==========\n",
    "def prepare_image_features(filename, path):\n",
    "    try:\n",
    "        img = fast_load(path)\n",
    "        color_hist = calc_histogram(img)\n",
    "        img_hash = calc_hash(img)\n",
    "        resolution = f\"{img.shape[1]}x{img.shape[0]}\"\n",
    "        file_size = os.path.getsize(path)\n",
    "        return (filename, path, img, color_hist, img_hash, resolution, file_size)\n",
    "    except Exception as e:\n",
    "        tb = traceback.format_exc()\n",
    "        return (filename, path, None, None, None, None, None, f\"{e} | Traceback:\\n{tb}\")\n",
    "\n",
    "# ========== MAIN ==========\n",
    "def main():\n",
    "    image_paths = list(image_generator(PHOTO_FOLDER))\n",
    "    logfile = open(LOG_FILE, \"a\", encoding=\"utf-8\")\n",
    "\n",
    "    batch_meta = []\n",
    "    batch_images = []\n",
    "    batch_entries = []\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "        futures = [executor.submit(prepare_image_features, fname, path) for fname, path in image_paths]\n",
    "\n",
    "        for future in tqdm(as_completed(futures), total=len(futures), desc=\"Verarbeitung\", unit=\"Bild\"):\n",
    "            result = future.result()\n",
    "            if len(result) == 8:  # Fehlerfall\n",
    "                fname, path, *_ , err = result\n",
    "                logfile.write(f\"{fname} ❌ {err}\\n\")\n",
    "                continue\n",
    "\n",
    "            filename, path, img, color_hist, img_hash, resolution, size = result\n",
    "            batch_meta.append((filename, path, color_hist, img_hash, resolution, size))\n",
    "            batch_images.append(img)\n",
    "\n",
    "            if len(batch_images) >= BATCH_SIZE:\n",
    "                process_batch(batch_meta, batch_images, batch_entries, logfile)\n",
    "                batch_meta.clear()\n",
    "                batch_images.clear()\n",
    "                batch_entries.clear()\n",
    "\n",
    "    # letzter Batch\n",
    "    if batch_images:\n",
    "        process_batch(batch_meta, batch_images, batch_entries, logfile, final=True)\n",
    "\n",
    "    logfile.write(f\"[{datetime.now()}] ✓ Fertig\\n\")\n",
    "    logfile.close()\n",
    "    conn.close()\n",
    "\n",
    "# ========== Batch Processing mit PCA + UMAP ==========\n",
    "def process_batch(batch_meta, batch_images, batch_entries, logfile, final=False):\n",
    "    try:\n",
    "        embs = extract_embeddings(batch_images)\n",
    "        pca = PCA(n_components=100)\n",
    "        embs_pca = pca.fit_transform(embs)\n",
    "\n",
    "        reducer = umap.UMAP(n_components=2, n_jobs=-1, random_state=None)\n",
    "        coords = reducer.fit_transform(embs_pca)\n",
    "\n",
    "        for meta, emb, emb_pca, (x, y) in zip(batch_meta, embs, embs_pca, coords):\n",
    "            filename, path, hist, img_hash, resolution, size = meta\n",
    "            hist_str = \",\".join([str(round(v, 6)) for v in hist])\n",
    "\n",
    "            # Speichern Original-Embedding\n",
    "            emb_path = os.path.join(EMBEDDING_DIR, f\"{filename}.npy\")\n",
    "            np.save(emb_path, emb)\n",
    "\n",
    "            # Speichern PCA-Embedding\n",
    "            pca_path = os.path.join(EMBEDDING_PCA_DIR, f\"{filename}_pca.npy\")\n",
    "            np.save(pca_path, emb_pca)\n",
    "\n",
    "            # In DB einfügen\n",
    "            batch_entries.append((\n",
    "                filename, path, hist_str, emb_path, img_hash, resolution, size,\n",
    "                None, None, pca_path, float(x), float(y)\n",
    "            ))\n",
    "\n",
    "        save_batch_to_db(batch_entries)\n",
    "        msg = \"letzter Batch gespeichert\" if final else f\"{len(batch_entries)} ✓ gespeichert\"\n",
    "        logfile.write(f\"{msg}\\n\")\n",
    "    except Exception as e:\n",
    "        logfile.write(f\"❌ Fehler im Batch: {e}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ========== Profiling + Ausführung ==========\n",
    "if __name__ == \"__main__\":\n",
    "    with cProfile.Profile() as pr:\n",
    "        main()\n",
    "\n",
    "    # Textausgabe\n",
    "    with open(\"profiling_results.txt\", \"w\") as f:\n",
    "        stats = pstats.Stats(pr, stream=f)\n",
    "        stats.sort_stats(\"cumtime\").print_stats()  # Alle Funktionen\n",
    "\n",
    "    # Binärspeicherung\n",
    "    stats.dump_stats(\"profiling_results.prof\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae574a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
